# Security Review: BMTC Transit API v0.2.0 (STRIDE-lite)

**Date:** 2025-10-22
**Reviewer:** Security-Privacy Agent
**Scope:** Main branch (commit bfc55bf), version 0.2.0 (Global Aggregation + Rate Limiting)
**Codebase:** `/home/karan-kinariwala/Dropbox/KARAN/1-Projects/bmtc-transit-app`

---

## Executive Summary

**Overall Risk:** MEDIUM (3 HIGH findings, 5 MEDIUM findings, 2 LOW findings)

The BMTC Transit API demonstrates strong privacy-by-design principles with intentional authentication boundaries and device anonymization. However, **three HIGH-severity findings require immediate remediation before production deployment**:

1. **Body hash verification missing** for idempotency conflicts (Tampering vulnerability)
2. **Rate limiting disabled by default** (DoS vulnerability)
3. **IP address logging in rate limit fallback** (Privacy/Information Disclosure)

The system correctly enforces authentication on POST endpoints, prevents `device_bucket` exposure in responses, and implements outlier rejection. With the identified fixes, this system meets privacy-focused design goals.

**Recommendation:** Address HIGH findings before production deployment. MEDIUM findings should be tracked for next release.

---

## Changes Reviewed

- **File:** `backend/app/auth.py` (lines 12-19)
  - **Summary:** Bearer token validation for POST endpoints
  - **STRIDE:** S (Spoofing), I (Information Disclosure)

- **File:** `backend/app/idempotency.py` (lines 25-82)
  - **Summary:** Idempotency key storage and retrieval
  - **STRIDE:** T (Tampering), R (Repudiation)

- **File:** `backend/app/rate_limit.py` (lines 19-311)
  - **Summary:** Token bucket rate limiting with IP fallback
  - **STRIDE:** D (DoS), I (Information Disclosure)

- **File:** `backend/app/routes.py` (lines 38-192, 195-335)
  - **Summary:** POST /v1/ride_summary and GET endpoints
  - **STRIDE:** All categories

- **File:** `backend/app/config.py` (lines 8-38)
  - **Summary:** Configuration with feature flags
  - **STRIDE:** E (Elevation), D (DoS)

- **File:** `backend/app/models.py` (lines 8-160)
  - **Summary:** Pydantic request/response schemas
  - **STRIDE:** I (Information Disclosure), T (Tampering)

- **File:** `backend/app/learning.py` (lines 202-238)
  - **Summary:** Rejection logging with device_bucket
  - **STRIDE:** I (Information Disclosure), R (Repudiation)

- **File:** `backend/app/schema.sql` (lines 179-253)
  - **Summary:** Database schema with privacy-preserving fields
  - **STRIDE:** I (Information Disclosure), R (Repudiation)

---

## Findings

### [HIGH] Finding 1: Idempotency Body Hash Verification Missing

**Category:** T (Tampering)
**Location:** `backend/app/routes.py:56-65`, `backend/app/idempotency.py:25-57`
**Risk:** Clients can submit different payloads with the same idempotency key without detection. Attacker could replay idempotency keys with modified segment data, bypassing outlier detection and poisoning ETA statistics.

**Evidence:**
```python
# backend/app/routes.py:56-65
if idempotency_key:
    cached_response = check_idempotency_key(idempotency_key)
    if cached_response:
        # Return cached response (409 Conflict with cached result)
        logger.info(f"Idempotent replay detected: {idempotency_key}")
        # For now, return success with zero rejected count (client should cache response)
        response = RideSummaryResponse(
            accepted_segments=0, rejected_segments=0, rejected_by_reason={}
        )
        return response
```

**Problem:** The code stores `response_hash` (line 209 in `schema.sql`) but never computes or verifies the **request body hash** on replay. The CLAUDE.md specification states: "Body hash computed and stored; 409 Conflict on hash mismatch" but this is not implemented.

**Mitigation:**

```python
# backend/app/routes.py:56-65 (CORRECTED)
if idempotency_key:
    from app.idempotency import compute_body_hash

    # Compute hash of current request body
    body_hash = compute_body_hash(ride.model_dump())

    cached_response = check_idempotency_key(idempotency_key)
    if cached_response:
        # Verify body hash matches
        stored_hash = cached_response.get("body_hash")
        if stored_hash and stored_hash != body_hash:
            # Body changed - return 409 Conflict
            logger.warning(f"Idempotency key reused with different body: {idempotency_key}")
            raise HTTPException(
                status_code=409,
                detail="Idempotency key already used with different request body"
            )

        # Body matches - return cached response
        logger.info(f"Idempotent replay detected: {idempotency_key}")
        response = RideSummaryResponse(
            accepted_segments=cached_response["accepted_segments"],
            rejected_segments=cached_response["rejected_segments"],
            rejected_by_reason=cached_response["rejected_by_reason"]
        )
        return response
```

**Update `backend/app/idempotency.py`:**
```python
def compute_body_hash(body_dict: dict) -> str:
    """Compute SHA256 hash of request body for verification.

    Args:
        body_dict: Request body as dictionary

    Returns:
        SHA256 hex digest
    """
    body_json = json.dumps(body_dict, sort_keys=True)
    return hashlib.sha256(body_json.encode()).hexdigest()


def check_idempotency_key(idempotency_key: str) -> Optional[dict]:
    """Check if idempotency key exists and return cached response if found."""
    settings = get_settings()
    conn = get_connection(settings.db_path)
    cursor = conn.cursor()

    # Check TTL
    ttl_seconds = settings.idempotency_ttl_hours * 3600
    min_timestamp = int(time.time()) - ttl_seconds

    cursor.execute(
        """
        SELECT response_hash, body_hash FROM idempotency_keys
        WHERE key = ? AND submitted_at >= ?
        """,
        (idempotency_key, min_timestamp),
    )
    row = cursor.fetchone()
    conn.close()

    if row:
        # Return both hashes for verification
        return {"response_hash": row[0], "body_hash": row[1]}

    return None


def store_idempotency_key(idempotency_key: str, body_data: dict, response_data: dict) -> None:
    """Store idempotency key with body and response hashes."""
    settings = get_settings()
    conn = get_connection(settings.db_path)
    cursor = conn.cursor()

    body_hash = compute_body_hash(body_data)
    response_hash = compute_response_hash(response_data)

    cursor.execute(
        """
        INSERT OR REPLACE INTO idempotency_keys (key, submitted_at, response_hash, body_hash)
        VALUES (?, ?, ?, ?)
        """,
        (idempotency_key, int(time.time()), response_hash, body_hash),
    )
    conn.commit()
    conn.close()
```

**Update schema:**
```sql
-- backend/app/schema.sql (line 206-210)
CREATE TABLE IF NOT EXISTS idempotency_keys (
    key TEXT PRIMARY KEY,
    submitted_at INTEGER NOT NULL,
    response_hash TEXT NOT NULL,
    body_hash TEXT NOT NULL  -- ADD THIS FIELD
);
```

**Verification:**
```bash
# Test idempotency tampering detection
curl -X POST https://api.example.com/v1/ride_summary \
  -H "Authorization: Bearer $API_KEY" \
  -H "Idempotency-Key: test-key-123" \
  -H "Content-Type: application/json" \
  -d '{"route_id": "335E", "direction_id": 0, "segments": [...]}'

# Replay with DIFFERENT body (should return 409)
curl -X POST https://api.example.com/v1/ride_summary \
  -H "Authorization: Bearer $API_KEY" \
  -H "Idempotency-Key: test-key-123" \
  -H "Content-Type: application/json" \
  -d '{"route_id": "500C", "direction_id": 1, "segments": [...]}'  # Different data

# Expected: HTTP 409 Conflict
```

---

### [HIGH] Finding 2: Rate Limiting Disabled by Default

**Category:** D (Denial of Service)
**Location:** `backend/app/config.py:30`, `backend/app/rate_limit.py:227-230`
**Risk:** Production API exposed to abuse without rate limiting. A single attacker can submit unlimited ride data, exhausting database resources and poisoning statistics with fake observations.

**Evidence:**
```python
# backend/app/config.py:30
rate_limit_enabled: bool = False  # Feature flag for safe rollout
```

```python
# backend/app/rate_limit.py:227-230
settings = get_settings()
if not settings.rate_limit_enabled:
    # Pass through without rate limiting
    return await call_next(request)
```

**Impact:**
- Unlimited POST /v1/ride_summary submissions
- Database write amplification (3-5M row `segment_stats` table grows unbounded)
- Statistical poisoning via mass fake ride submissions
- No per-device accountability

**Mitigation:**

**Option 1 (Recommended): Enable by default with gradual rollout**
```python
# backend/app/config.py:30
rate_limit_enabled: bool = True  # CHANGED: Enable by default
rate_limit_per_hour: int = 500  # Conservative limit for production
```

**Option 2: Add deployment checklist requirement**
Create `docs/DEPLOYMENT_CHECKLIST.md`:
```markdown
## Pre-Production Security Checklist

- [ ] Set `BMTC_RATE_LIMIT_ENABLED=true` in production environment
- [ ] Verify `BMTC_RATE_LIMIT_PER_HOUR` is set (default: 500)
- [ ] Test rate limit enforcement with curl (see below)
- [ ] Configure monitoring alert for rate limit 429 responses
```

**Option 3: Runtime validation on startup**
```python
# backend/app/main.py (add to lifespan function)
@asynccontextmanager
async def lifespan(app: FastAPI):
    """Startup and shutdown hooks."""
    settings = get_settings()

    # WARNING: Rate limiting disabled in production
    if not settings.rate_limit_enabled:
        logger.warning(
            "SECURITY WARNING: Rate limiting is DISABLED. "
            "Set BMTC_RATE_LIMIT_ENABLED=true for production deployment."
        )

    init_db(settings.db_path)
    state.set_startup_time(int(time.time()))
    yield
```

**Verification:**
```bash
# Test rate limiting (requires rate_limit_enabled=true)
for i in {1..502}; do
  curl -s -o /dev/null -w "%{http_code}\n" -X POST https://api.example.com/v1/ride_summary \
    -H "Authorization: Bearer $API_KEY" \
    -H "Idempotency-Key: $(uuidgen)" \
    -d '{"route_id": "335E", "direction_id": 0, "device_bucket": "abc123...", "segments": [...]}'
done

# Expected: First 500 return 200, next 2 return 429
# Check X-RateLimit-* headers in response
```

---

### [HIGH] Finding 3: IP Address Logging in Rate Limit Fallback

**Category:** I (Information Disclosure) / Privacy Violation
**Location:** `backend/app/rate_limit.py:49-51`, `backend/app/rate_limit.py:280-282`
**Risk:** User IP addresses logged when `device_bucket` extraction fails, creating a privacy risk. CLAUDE.md states: "IP addresses must not be logged alongside ride data." IP fallback creates linkable identifier for tracking.

**Evidence:**
```python
# backend/app/rate_limit.py:49-51
# Priority 3: Fallback to IP address
client_ip = request.client.host if request.client else "unknown"
return f"ip:{client_ip}"
```

```python
# backend/app/rate_limit.py:280-282
logger.warning(
    f"Rate limit exceeded for {bucket_type} bucket (id: {bucket_id[:8]}...)"
)
```

**Problem:** When `device_bucket` is not provided, the system falls back to IP-based rate limiting and stores `ip:<address>` in the `rate_limit_buckets` table. This violates privacy-by-design principles and creates a tracking vector.

**Impact:**
- IP addresses persist in database (no TTL on `rate_limit_buckets`)
- Correlation risk: IP + timestamp + ride patterns = user re-identification
- Log analysis can reveal user activity patterns
- Violates privacy requirement: "IP addresses must not be logged alongside ride data"

**Mitigation:**

**Option 1 (Recommended): Reject requests without device_bucket**
```python
# backend/app/rate_limit.py:19-52 (CORRECTED)
async def extract_bucket_id(request: Request) -> str:
    """Extract bucket_id from request body (REQUIRED).

    Args:
        request: FastAPI request object

    Returns:
        bucket_id string (device_bucket hash)

    Raises:
        HTTPException: 400 if device_bucket not provided
    """
    try:
        body_bytes = await request.body()
        if body_bytes:
            body = json.loads(body_bytes.decode())

            # Check top-level device_bucket field (v1 spec)
            if "device_bucket" in body and body["device_bucket"]:
                return body["device_bucket"]

            # Check segments for backward compat (deprecated)
            if "segments" in body and isinstance(body["segments"], list):
                for segment in body["segments"]:
                    if isinstance(segment, dict) and segment.get("device_bucket"):
                        logger.warning("device_bucket in segments is deprecated")
                        return segment["device_bucket"]
    except Exception as e:
        logger.warning(f"Failed to extract device_bucket from body: {e}")

    # REJECT instead of IP fallback
    raise HTTPException(
        status_code=400,
        detail="device_bucket field is required for rate limiting. See /v1/config for requirements."
    )
```

**Option 2: Hash IP addresses (if fallback required for backward compat)**
```python
# backend/app/rate_limit.py:49-51 (ALTERNATIVE)
import hashlib

# Priority 3: Fallback to HASHED IP (not raw IP)
client_ip = request.client.host if request.client else "unknown"
ip_hash = hashlib.sha256(f"{client_ip}:daily-salt".encode()).hexdigest()
return f"ip:{ip_hash[:16]}"  # Truncated hash, no raw IP
```

**Update logging to redact bucket IDs:**
```python
# backend/app/rate_limit.py:280-282 (CORRECTED)
logger.warning(
    f"Rate limit exceeded for {bucket_type} bucket "
    f"(segment_id: {segment_id}, bin_id: {bin_id})"  # NO bucket_id logged
)
```

**Verification:**
```bash
# Test rejection when device_bucket missing
curl -X POST https://api.example.com/v1/ride_summary \
  -H "Authorization: Bearer $API_KEY" \
  -H "Idempotency-Key: $(uuidgen)" \
  -d '{"route_id": "335E", "direction_id": 0, "segments": [...]}'  # NO device_bucket

# Expected: HTTP 400 with error message

# Test acceptance with device_bucket
curl -X POST https://api.example.com/v1/ride_summary \
  -H "Authorization: Bearer $API_KEY" \
  -H "Idempotency-Key: $(uuidgen)" \
  -d '{"route_id": "335E", "direction_id": 0, "device_bucket": "abc123...", "segments": [...]}'

# Expected: HTTP 200

# Verify no raw IPs in database
sqlite3 bmtc.db "SELECT bucket_id FROM rate_limit_buckets WHERE bucket_id LIKE 'ip:%';"
# Expected: Empty result (no raw IPs) OR hashed IPs only
```

---

### [MEDIUM] Finding 4: Timing Attack on Bearer Token Validation

**Category:** S (Spoofing), I (Information Disclosure)
**Location:** `backend/app/auth.py:17`
**Risk:** String comparison uses `!=` operator which may allow timing attacks to leak API key length or character positions.

**Evidence:**
```python
# backend/app/auth.py:17
if credentials.credentials != settings.api_key:
    raise HTTPException(status_code=401, detail="Invalid API key")
```

**Mitigation:**
```python
# backend/app/auth.py:12-19 (CORRECTED)
import secrets

def verify_token(
    credentials: HTTPAuthorizationCredentials = Security(security),
) -> bool:
    """Verify Bearer token against configured API key using constant-time comparison."""
    settings = get_settings()

    # Use secrets.compare_digest for constant-time comparison
    if not secrets.compare_digest(credentials.credentials, settings.api_key):
        raise HTTPException(status_code=401, detail="Invalid API key")

    return True
```

**Verification:**
```bash
# Timing attack is difficult to verify in practice, but code review confirms fix
# Test authentication still works:
curl -H "Authorization: Bearer $CORRECT_API_KEY" https://api.example.com/v1/ride_summary
# Expected: 200 (if other requirements met)

curl -H "Authorization: Bearer wrong_key" https://api.example.com/v1/ride_summary
# Expected: 401
```

---

### [MEDIUM] Finding 5: Device Bucket Exposure in Rejection Log

**Category:** I (Information Disclosure)
**Location:** `backend/app/learning.py:209`, `backend/app/schema.sql:233`
**Risk:** `device_bucket` stored in `rejection_log` table (30-day retention). While not exposed via API, database access by admins could enable user tracking across rides.

**Evidence:**
```sql
-- backend/app/schema.sql:227-238
CREATE TABLE IF NOT EXISTS rejection_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    segment_id INTEGER NOT NULL,
    bin_id INTEGER NOT NULL,
    reason TEXT NOT NULL,
    submitted_at INTEGER NOT NULL,
    device_bucket TEXT,  -- PRIVACY RISK: linkable across rides
    duration_sec REAL,
    mapmatch_conf REAL,
    ...
);
```

**Impact:**
- Admin with database access can query all rejections for a device
- Cross-ride correlation possible within 30-day retention window
- Violates principle of minimal data collection for privacy

**Mitigation (choose one):**

**Option 1: Remove device_bucket from rejection_log**
```sql
-- Migration: Remove device_bucket from rejection_log
ALTER TABLE rejection_log DROP COLUMN device_bucket;
```

```python
# backend/app/learning.py:202-238 (CORRECTED)
def log_rejection(
    conn,
    segment_id: int,
    bin_id: int,
    reason: str,
    duration_sec: float,
    mapmatch_conf: float,
    device_bucket: str | None = None,  # IGNORED (not stored)
) -> None:
    """Log rejected observation WITHOUT device_bucket."""
    cursor = conn.cursor()
    cursor.execute(
        """
        INSERT INTO rejection_log (segment_id, bin_id, reason, submitted_at, duration_sec, mapmatch_conf)
        VALUES (?, ?, ?, ?, ?, ?)
        """,
        (segment_id, bin_id, reason, int(time.time()), duration_sec, mapmatch_conf),
    )
    conn.commit()
```

**Option 2: Hash device_bucket in rejection_log**
```python
# backend/app/learning.py:202-238 (ALTERNATIVE)
import hashlib

def log_rejection(
    conn,
    segment_id: int,
    bin_id: int,
    reason: str,
    duration_sec: float,
    mapmatch_conf: float,
    device_bucket: str | None = None,
) -> None:
    """Log rejected observation with HASHED device_bucket (for abuse detection only)."""
    cursor = conn.cursor()

    # Hash device_bucket to prevent tracking
    device_bucket_hash = None
    if device_bucket:
        device_bucket_hash = hashlib.sha256(f"{device_bucket}:rejection".encode()).hexdigest()[:16]

    cursor.execute(
        """
        INSERT INTO rejection_log (segment_id, bin_id, reason, submitted_at, device_bucket, duration_sec, mapmatch_conf)
        VALUES (?, ?, ?, ?, ?, ?, ?)
        """,
        (segment_id, bin_id, reason, int(time.time()), device_bucket_hash, duration_sec, mapmatch_conf),
    )
    conn.commit()
```

**Verification:**
```bash
# Check rejection_log does NOT contain raw device_bucket values
sqlite3 bmtc.db "SELECT DISTINCT device_bucket FROM rejection_log LIMIT 5;"
# Expected: NULL or short hashes (not 64-char SHA256 values)
```

---

### [MEDIUM] Finding 6: Idempotency Key Cleanup Not Integrated

**Category:** R (Repudiation), D (DoS)
**Location:** `backend/app/idempotency.py:84-104`, `backend/deploy/bmtc-retention.service`
**Risk:** `cleanup_expired_keys()` function exists but is not called by any systemd timer or cron job. Idempotency keys accumulate indefinitely, causing database bloat and potential DoS.

**Evidence:**
```python
# backend/app/idempotency.py:84-104
def cleanup_expired_keys() -> int:
    """Remove expired idempotency keys (older than TTL).

    Returns:
        Number of keys deleted
    """
    # Function defined but never called
```

**Mitigation:**

**Option 1: Add to retention systemd service**
```bash
# backend/deploy/bmtc-retention.service (ADD THIS)
[Service]
ExecStart=/bin/bash -c '\
  source /etc/bmtc-api/env && \
  cd /opt/bmtc-api/backend && \
  /opt/bmtc-api/.venv/bin/python -c "from app.idempotency import cleanup_expired_keys; print(f\"Deleted {cleanup_expired_keys()} expired idempotency keys\")"'
```

**Option 2: Add cleanup endpoint (admin-only)**
```python
# backend/app/routes.py (ADD THIS)
@router.post("/admin/cleanup", dependencies=[Depends(verify_admin_token)])
async def cleanup_expired_data():
    """Clean up expired idempotency keys and old rejection logs (admin-only)."""
    from app.idempotency import cleanup_expired_keys

    deleted_keys = cleanup_expired_keys()

    # Also clean up old rejection logs
    settings = get_settings()
    conn = get_connection(settings.db_path)
    cursor = conn.cursor()

    retention_seconds = settings.rejection_log_retention_days * 86400
    min_timestamp = int(time.time()) - retention_seconds

    cursor.execute("DELETE FROM rejection_log WHERE submitted_at < ?", (min_timestamp,))
    deleted_logs = cursor.rowcount
    conn.commit()
    conn.close()

    return {
        "deleted_idempotency_keys": deleted_keys,
        "deleted_rejection_logs": deleted_logs
    }
```

**Verification:**
```bash
# Test cleanup function manually
cd /home/karan-kinariwala/Dropbox/KARAN/1-Projects/bmtc-transit-app/backend
uv run python -c "from app.idempotency import cleanup_expired_keys; print(cleanup_expired_keys())"

# Check systemd timer is active
sudo systemctl status bmtc-retention.timer
sudo journalctl -u bmtc-retention.service -n 50
```

---

### [MEDIUM] Finding 7: No Request Body Size Limit Enforced

**Category:** D (Denial of Service)
**Location:** `backend/app/main.py`, `backend/app/routes.py:68-72`
**Risk:** While `max_segments_per_ride` is validated (50 segments), there is no FastAPI middleware limiting total request body size. Attacker could send multi-GB payloads with 50 segments containing extremely long strings.

**Evidence:**
```python
# backend/app/routes.py:68-72
if len(ride.segments) > settings.max_segments_per_ride:
    raise HTTPException(
        status_code=400,
        detail=f"Too many segments ({len(ride.segments)}), max is {settings.max_segments_per_ride}",
    )
```

**Problem:** No protection against:
- Each segment with 10MB `from_stop_id` string
- Total payload = 50 segments × 10MB = 500MB
- Exhausts memory during Pydantic parsing before validation runs

**Mitigation:**
```python
# backend/app/main.py (ADD AFTER LINE 46)
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.responses import JSONResponse

class RequestSizeLimitMiddleware(BaseHTTPMiddleware):
    """Limit request body size to prevent DoS."""

    async def dispatch(self, request, call_next):
        # Limit body size to 10MB
        MAX_BODY_SIZE = 10 * 1024 * 1024  # 10MB

        content_length = request.headers.get("content-length")
        if content_length and int(content_length) > MAX_BODY_SIZE:
            return JSONResponse(
                status_code=413,
                content={
                    "error": "payload_too_large",
                    "message": f"Request body exceeds maximum size of {MAX_BODY_SIZE} bytes",
                }
            )

        return await call_next(request)

# Add middleware BEFORE RateLimitMiddleware
app.add_middleware(RequestSizeLimitMiddleware)
app.add_middleware(RateLimitMiddleware)
```

**Verification:**
```bash
# Test body size limit
dd if=/dev/zero bs=1M count=11 | curl -X POST https://api.example.com/v1/ride_summary \
  -H "Authorization: Bearer $API_KEY" \
  -H "Content-Type: application/json" \
  --data-binary @- -w "%{http_code}\n"

# Expected: HTTP 413 Payload Too Large
```

---

### [MEDIUM] Finding 8: SQL Injection Risk in Dynamic Queries (Low Likelihood)

**Category:** T (Tampering), E (Elevation of Privilege)
**Location:** `backend/app/routes.py:98-108`, `backend/app/routes.py:209-214`
**Risk:** All queries use parameterized statements (safe), but dynamic query construction patterns could introduce SQL injection if code changes in future.

**Evidence:**
```python
# backend/app/routes.py:98-108 (SAFE - parameterized)
cursor.execute(
    """
    SELECT segment_id FROM segments
    WHERE route_id = ? AND direction_id = ? AND from_stop_id = ? AND to_stop_id = ?
    """,
    (ride.route_id, ride.direction_id, segment.from_stop_id, segment.to_stop_id),
)
```

**Current Status:** ✅ **All queries are parameterized and safe**

**Recommendation (preventive):** Add SQL injection testing to CI/CD pipeline:
```python
# backend/tests/test_security.py (NEW FILE)
import pytest
from fastapi.testclient import TestClient

def test_sql_injection_prevention(client: TestClient, auth_headers):
    """Verify SQL injection attempts are blocked by parameterization."""

    # Test route_id injection
    malicious_payload = {
        "route_id": "335E'; DROP TABLE segments; --",
        "direction_id": 0,
        "device_bucket": "abc123" * 8,
        "segments": [{
            "from_stop_id": "20558",
            "to_stop_id": "29374",
            "duration_sec": 120.0,
            "observed_at_utc": "2025-10-22T10:00:00Z"
        }]
    }

    response = client.post("/v1/ride_summary", json=malicious_payload, headers=auth_headers)

    # Should return 422 (unknown segment) not 500 (SQL error)
    assert response.status_code == 422

    # Verify segments table still exists
    # (Add database check here)
```

**Verification:**
```bash
# Run security tests
cd backend && uv run pytest tests/test_security.py -v
```

---

### [LOW] Finding 9: Error Messages May Leak Schema Information

**Category:** I (Information Disclosure)
**Location:** `backend/app/routes.py:113-116`, `backend/app/routes.py:219`
**Risk:** Error messages expose database schema details (segment_id, table names) which could aid attackers in crafting exploits.

**Evidence:**
```python
# backend/app/routes.py:113-116
if row is None:
    conn.close()
    raise HTTPException(
        status_code=422,
        detail=f"Unknown segment: {segment.from_stop_id} -> {segment.to_stop_id}",
    )
```

**Current Message:** Exposes internal stop IDs directly
**Recommendation:** Generic error messages for external API

**Mitigation:**
```python
# backend/app/routes.py:113-116 (CORRECTED)
if row is None:
    conn.close()
    logger.info(f"Unknown segment rejected: {segment.from_stop_id} -> {segment.to_stop_id}")
    raise HTTPException(
        status_code=422,
        detail="Invalid segment combination. Verify route, direction, and stop IDs.",
    )
```

**Impact:** LOW - Stop IDs are from public GTFS data, not sensitive
**Priority:** Fix in next release

---

### [LOW] Finding 10: No HTTPS Enforcement in Application

**Category:** S (Spoofing), I (Information Disclosure)
**Location:** Deployment configuration
**Risk:** Application does not enforce HTTPS, relying on Cloudflare Tunnel. If tunnel misconfigured or bypassed, API key and ride data transmitted in plaintext.

**Evidence:** No HTTPS redirect middleware in `backend/app/main.py`

**Mitigation:**
```python
# backend/app/main.py (ADD AFTER LINE 46)
from fastapi.middleware.httpsredirect import HTTPSRedirectMiddleware

# Force HTTPS in production
if settings.server_version != "0.0.0-dev":  # Not in dev mode
    app.add_middleware(HTTPSRedirectMiddleware)
```

**Alternative:** Configure at Cloudflare Tunnel level (already done if using CF Tunnel)

**Verification:**
```bash
# Test HTTP redirect (if middleware added)
curl -I http://api.example.com/v1/health
# Expected: HTTP 307 redirect to https://
```

---

## STRIDE Summary

| Category | Status | Assessment |
|----------|--------|------------|
| **S - Spoofing** | ⚠️ MEDIUM | Bearer token validation works but uses timing-vulnerable comparison (F4). Auth boundary correctly enforced (POST=required, GET=open). |
| **T - Tampering** | ❌ HIGH | Idempotency body hash verification missing (F1). All queries use parameterized statements (safe from SQL injection). |
| **R - Repudiation** | ⚠️ MEDIUM | Idempotency keys stored but cleanup not scheduled (F6). Minimal logging preserves admin troubleshooting capability. |
| **I - Information Disclosure** | ❌ HIGH | IP addresses logged in rate limit fallback (F3). device_bucket correctly excluded from GET responses. device_bucket in rejection_log (F5). Error messages may leak schema (F9). |
| **D - Denial of Service** | ❌ HIGH | Rate limiting disabled by default (F2). No request body size limit (F7). Token bucket algorithm correct. Outlier rejection prevents statistical poisoning. |
| **E - Elevation of Privilege** | ✅ PASS | No admin endpoints exposed via HTTP. Database permissions not checked (assume deployment guide followed). No debug flags controllable via HTTP. |

---

## Operator Checklist

### 1. Verify Authentication Boundaries
```bash
# POST without auth should fail
curl -X POST https://api.example.com/v1/ride_summary \
  -H "Content-Type: application/json" \
  -d '{"route_id": "335E", "direction_id": 0, "segments": []}' \
  -w "\nStatus: %{http_code}\n"
# Expected: Status: 401

# GET without auth should succeed
curl https://api.example.com/v1/config -w "\nStatus: %{http_code}\n"
# Expected: Status: 200
```

### 2. Verify device_bucket Privacy
```bash
# Check device_bucket NOT in GET /v1/eta response
curl -s "https://api.example.com/v1/eta?route_id=335E&direction_id=0&from_stop_id=20558&to_stop_id=29374" | \
  jq 'has("device_bucket")'
# Expected: false

# Check database for device_bucket in GET responses (should be none)
sqlite3 bmtc.db "SELECT * FROM segment_stats LIMIT 1;"
# Verify: No device_bucket column in segment_stats
```

### 3. Verify Rate Limiting Status
```bash
# Check if rate limiting is enabled
curl -s https://api.example.com/v1/config | jq '.rate_limit_enabled'
# Expected: true (if HIGH finding F2 fixed)

# Test rate limit headers
curl -I -X POST https://api.example.com/v1/ride_summary \
  -H "Authorization: Bearer $API_KEY" \
  -H "Idempotency-Key: $(uuidgen)" \
  -d '{"route_id": "335E", "direction_id": 0, "device_bucket": "abc"*64, "segments": [...]}'
# Expected headers:
#   X-RateLimit-Limit: 500
#   X-RateLimit-Remaining: <number>
#   X-RateLimit-Reset: <timestamp>
```

### 4. Verify Idempotency Correctness
```bash
# Submit ride with idempotency key
IDEMP_KEY=$(uuidgen)
curl -X POST https://api.example.com/v1/ride_summary \
  -H "Authorization: Bearer $API_KEY" \
  -H "Idempotency-Key: $IDEMP_KEY" \
  -d @ride_payload.json

# Replay with SAME body (should return cached response)
curl -X POST https://api.example.com/v1/ride_summary \
  -H "Authorization: Bearer $API_KEY" \
  -H "Idempotency-Key: $IDEMP_KEY" \
  -d @ride_payload.json
# Expected: Same response as first call

# Replay with DIFFERENT body (should return 409 if F1 fixed)
curl -X POST https://api.example.com/v1/ride_summary \
  -H "Authorization: Bearer $API_KEY" \
  -H "Idempotency-Key: $IDEMP_KEY" \
  -d @different_payload.json
# Expected: HTTP 409 Conflict
```

### 5. Check for IP Logging (Privacy Audit)
```bash
# Grep logs for IP addresses alongside ride data
sudo journalctl -u bmtc-api -n 1000 | grep -E '[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}' | \
  grep -i 'segment\|ride\|duration'
# Expected: No matches (no IP logging with ride data)

# Check rate_limit_buckets for raw IPs
sqlite3 bmtc.db "SELECT bucket_id FROM rate_limit_buckets WHERE bucket_id LIKE 'ip:%' LIMIT 10;"
# Expected: Empty result (if F3 fixed) OR hashed IPs only
```

### 6. Verify Outlier Rejection
```bash
# Check rejection_log has entries
sqlite3 bmtc.db "SELECT reason, COUNT(*) FROM rejection_log GROUP BY reason;"
# Expected output:
#   low_mapmatch_conf|<count>
#   outlier|<count>

# Verify mapmatch_min_conf threshold
curl -s https://api.example.com/v1/config | jq '.mapmatch_min_conf'
# Expected: 0.7
```

### 7. Verify Retention Policy Execution
```bash
# Check systemd timer for retention cleanup
sudo systemctl status bmtc-retention.timer
sudo systemctl list-timers bmtc-retention.timer

# Check last cleanup execution
sudo journalctl -u bmtc-retention.service -n 20

# Verify old data is cleaned up
sqlite3 bmtc.db "SELECT COUNT(*) FROM idempotency_keys WHERE submitted_at < $(date -d '25 hours ago' +%s);"
# Expected: 0 (all keys >24h deleted)

sqlite3 bmtc.db "SELECT COUNT(*) FROM rejection_log WHERE submitted_at < $(date -d '31 days ago' +%s);"
# Expected: 0 (all logs >30d deleted)
```

### 8. Verify SQL Parameterization (Security Audit)
```bash
# Search for unsafe string concatenation in SQL queries
cd /home/karan-kinariwala/Dropbox/KARAN/1-Projects/bmtc-transit-app/backend/app
grep -r "execute.*f\"" *.py | grep -v "logger"
# Expected: No matches (all queries use ? placeholders)

# Check for f-strings in SQL
grep -r "f\".*SELECT\|INSERT\|UPDATE\|DELETE" *.py | grep -v "logger"
# Expected: No matches
```

### 9. Verify Logging Redaction
```bash
# Check logs do NOT contain device_bucket values (64-char hex)
sudo journalctl -u bmtc-api -n 1000 | grep -E '[a-f0-9]{64}'
# Expected: No matches (device_bucket never logged)

# Check logs do NOT contain API keys
sudo journalctl -u bmtc-api -n 1000 | grep -i 'bearer\|authorization'
# Expected: No raw tokens (only "Invalid API key" messages)
```

### 10. Production Deployment Security Checklist
```bash
# Verify environment variables set
grep BMTC_API_KEY /etc/bmtc-api/env
grep BMTC_RATE_LIMIT_ENABLED /etc/bmtc-api/env

# Verify database permissions
ls -l /var/lib/bmtc-api/bmtc.db
# Expected: -rw-r----- bmtc bmtc (owner: bmtc, not root)

# Verify service runs as non-root
systemctl show bmtc-api.service -p User
# Expected: User=bmtc

# Check Cloudflare Tunnel status (HTTPS enforcement)
sudo systemctl status cloudflared
```

---

## Recommendations

### Immediate Actions (Before Production)

1. **[HIGH]** Implement body hash verification for idempotency (Finding 1)
   - Add `body_hash` column to `idempotency_keys` table
   - Compute and verify hash on replays
   - Return HTTP 409 on mismatch

2. **[HIGH]** Enable rate limiting by default (Finding 2)
   - Set `rate_limit_enabled: bool = True` in config.py
   - Add startup warning if disabled
   - Test with 500+ requests to verify enforcement

3. **[HIGH]** Remove IP address logging (Finding 3)
   - Reject requests without `device_bucket` (recommended)
   - OR hash IP addresses if fallback required
   - Update rate limit middleware to enforce device_bucket

4. **[MEDIUM]** Fix timing attack on token validation (Finding 4)
   - Use `secrets.compare_digest()` for constant-time comparison

5. **[MEDIUM]** Schedule idempotency key cleanup (Finding 6)
   - Integrate `cleanup_expired_keys()` into bmtc-retention.service
   - Verify execution via journalctl

### Next Release (v0.3.0)

6. **[MEDIUM]** Remove or hash device_bucket in rejection_log (Finding 5)
7. **[MEDIUM]** Add request body size limit middleware (Finding 7)
8. **[LOW]** Generic error messages for API responses (Finding 9)
9. **[LOW]** Add HTTPS enforcement middleware (Finding 10)

### Continuous Monitoring

10. **Add security tests to CI/CD:**
    - SQL injection attempt tests
    - Authentication bypass tests
    - Rate limit enforcement tests
    - Idempotency correctness tests

11. **Set up monitoring alerts:**
    - Spike in HTTP 429 (rate limit exceeded)
    - Spike in HTTP 401 (auth failures = possible attack)
    - Spike in outlier rejections (possible poisoning attempt)
    - Device bucket with >10,000 observations (abuse detection)

---

## Sign-off

- [ ] **No HIGH or CRITICAL findings unresolved** (3 HIGH findings require fixes)
- [ ] **All MEDIUM findings have mitigation plan** (5 MEDIUM findings documented)
- [ ] **Privacy requirements verified** (device_bucket not in responses ✅, IP logging issue ❌)
- [ ] **Idempotency correctness verified** (storage works ✅, body hash missing ❌)
- [ ] **Rate limiting verified** (implementation correct ✅, disabled by default ❌)
- [ ] **Logging reviewed for PII leakage** (no payloads logged ✅, device_bucket in logs ❌)

**Overall Status:** ⚠️ **CONDITIONAL APPROVAL**
Fix 3 HIGH findings (F1, F2, F3) before production deployment. System demonstrates strong privacy-by-design with intentional authentication boundaries and device anonymization. With identified fixes, meets security requirements.

---

**Review Completed:** 2025-10-22
**Next Review:** After HIGH findings remediated (recommend within 7 days)
